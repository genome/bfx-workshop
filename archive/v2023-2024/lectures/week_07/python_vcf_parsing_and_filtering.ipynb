{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFX Workshop Week 7 - Parsing and Filtering with Python\n",
    "\n",
    "## Setup\n",
    "\n",
    "For this module we'll be working with a somatic exome VCF file created by the Mutect variant caller with some basic filtering already done. Let's create a working directory and download this file.\n",
    "\n",
    "Note: In the event that any `gs://` links break in the future, all files are mirrored at [box](https://wustl.box.com/s/iqmr943rbsxafjtk9ekftfx42ng6nqw7). To download, follow the link and use the download button in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $PWD\n",
    "!mkdir -p $PWD/bfx_workshop_week_7\n",
    "!docker run -v $PWD/bfx_workshop_week_7:/staging mgibio/data_downloader:0.1.0 gsutil -m cp gs://analysis-workflows-example-data/vcf_parsing_files/mutect.filtered.vcf.gz /staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the reference and tumor bam files used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD/bfx_workshop_week_7:/staging mgibio/data_downloader:0.1.0 gsutil -m cp gs://analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa /staging\n",
    "!docker run -v $PWD/bfx_workshop_week_7:/staging mgibio/data_downloader:0.1.0 gsutil -m cp gs://analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa.fai /staging\n",
    "!docker run -v $PWD/bfx_workshop_week_7:/staging mgibio/data_downloader:0.1.0 gsutil -m cp gs://analysis-workflows-example-data/vcf_parsing_files/tumor.bam /staging\n",
    "!docker run -v $PWD/bfx_workshop_week_7:/staging mgibio/data_downloader:0.1.0 gsutil -m cp gs://analysis-workflows-example-data/vcf_parsing_files/tumor.bam.bai /staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed up later steps, let's pull the Docker containers we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull mgibio/bam_readcount_helper-cwl:1.1.1\n",
    "!docker pull quay.io/biocontainers/vt:0.57721--hf74b74d_1\n",
    "!docker pull griffithlab/vatools:5.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Intro to VCF\n",
    "The [Variant Call Format (VCF)](https://samtools.github.io/hts-specs/VCFv4.4.pdf) is a text file format. It contains meta-information header lines and data lines with information about a position in the genome. It can optionally contain genotype information on samples for each position. Each data line will contain specific annotations applicable to a genomic position, genomic alteration, and/or sample(s) while the meta-data header lines will describe each annotation, what information they contain and their format.\n",
    "\n",
    "Meta-information header lines start with ## while data lines do not. \n",
    "\n",
    "Each data line represents a specific position and one or more genomic alterations at that position. The #CHROM header is a special header that works like a TSV header and describes each column of the data lines. The position is represented by the first two columns of the data line: CHROM and POS, the chromosome and genomic reference position, respecitively. The third column, ID, is a semicolon-separated list of unique identifiers, where available. The third and fourth column, REF and ALT, are the reference base(s) of the genomic alteration, followed by a comma-separated list of one or more alternate (variant) base(s). Each entry in the ALT list corresponds to a separate genomic alteration.\n",
    "\n",
    "## Example\n",
    "```\n",
    "##fileformat=VCFv4.2\n",
    "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
    "##INFO=<ID=MBQ,Number=R,Type=Integer,Description=\"median base quality\">\n",
    "##INFO=<ID=MMQ,Number=R,Type=Integer,Description=\"median mapping quality\">\n",
    "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
    "##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n",
    "##FORMAT=<ID=AF,Number=A,Type=Float,Description=\"Allele fractions of alternate alleles in the tumor\">\n",
    "##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\">\n",
    "#CHROM    POS    ID    REF    ALT    QUAL    FILTER    INFO    FORMAT    Exome_Normal    Exome_Tumor\n",
    "chr17\t2364457\t.\tT\tG\t.\tPASS\tMBQ=30,30;MMQ=60,60\tGT:AD:AF:DP\t0/0:85,0:0.011:85\t0/1:43,58:0.573:101\n",
    "```\n",
    "\n",
    "## Meta-information header lines\n",
    "\n",
    "Four types of meta-information header lines can be found in a VCF:\n",
    "\n",
    "- FILTER: Filters that have been applied to a data line\n",
    "- INFO: Per-variant data fields\n",
    "- FORMAT: Per-sample data fields\n",
    "- Other: Information applicable to the whole VCF\n",
    "\n",
    "### File format\n",
    "`##fileformat=VCFv4.2`\n",
    "\n",
    "### FILTER\n",
    "Each FILTER header describes one specific FILTER. The header includes the ID of the FILTER and a description.\n",
    "\n",
    "`##FILTER=<ID=ID,Description=\"description\">`\n",
    "\n",
    "e.g.:\n",
    "\n",
    "`##FILTER=<ID=PASS,Description=\"All filters passed\">`\n",
    "\n",
    "### INFO\n",
    "Each INFO header describes one specific INFO field. The header includes the ID of the INFO field, a Number value describing how many data points will be encoded in the field, a Type describing the data type of each data point in this field, and a Description. Source and Version are optional but can be used to descibe which tool added this field and the version of the tool.\n",
    "\n",
    "`##INFO=<ID=ID,Number=number,Type=type,Description=\"description\",Source=\"source\",Version=\"version\">`\n",
    "\n",
    "e.g.:\n",
    "\n",
    "`##INFO=<ID=MBQ,Number=R,Type=Integer,Description=\"median base quality\">`\n",
    "\n",
    "### FORMAT\n",
    "Each FORMAT header descibes one specific per-sample field. The header includes the ID of the per-sample field a Number value describing how many data points will be encoded in the field, a Type describing the data type of each data point in this field, and a Description.\n",
    "\n",
    "`##FORMAT=<ID=ID,Number=number,Type=type,Description=\"description\">`\n",
    "\n",
    "e.g.:\n",
    "\n",
    "`##FORMAT=<ID=AF,Number=A,Type=Float,Description=\"Allele fractions of alternate alleles in the tumor\">`\n",
    "\n",
    "### Other meta-information\n",
    "\n",
    "Generic information about the VCF can be stored in the header as key-value pairs. These are often used by various tools, e.g. variant callers, VEP, etc., to store information about how they were run.\n",
    "\n",
    "`##Key=Value`\n",
    "\n",
    "e.g.:\n",
    "\n",
    "`##GATKCommandLine=<ID=Mutect2,CommandLine=\"Mutect2 --tumor-sample Exome_Tumor --normal-sample Exome_Normal --output mutect.vcf.gz --input tumor.bam --input normal.bam --reference /storage1/fs1/bga/Active/gmsroot/gc2560/core/model_data/2887491634/build21f22873ebe0486c8e6f69c15435aa96/all_sequences.fa --f1r2-median-mq 50 --f1r2-min-bq 20 --f1r2-max-depth 200 --genotype-pon-sites false --genotype-germline-sites false --af-of-alleles-not-in-resource -1.0 --mitochondria-mode false --tumor-lod-to-emit 3.0 --initial-tumor-lod 2.0 --pcr-snv-qual 40 --pcr-indel-qual 40 --max-population-af 0.01 --downsampling-stride 1 --callable-depth 10 --max-suspicious-reads-per-alignment-start 0 --normal-lod 2.2 --ignore-itr-artifacts false --gvcf-lod-band -2.5 --gvcf-lod-band -2.0 --gvcf-lod-band -1.5 --gvcf-lod-band -1.0 --gvcf-lod-band -0.5 --gvcf-lod-band 0.0 --gvcf-lod-band 0.5 --gvcf-lod-band 1.0 --minimum-allele-fraction 0.0 --independent-mates false --disable-adaptive-pruning false --kmer-size 10 --kmer-size 25 --dont-increase-kmer-sizes-for-cycles false --allow-non-unique-kmers-in-ref false --num-pruning-samples 1 --min-dangling-branch-length 4 --recover-all-dangling-branches false --max-num-haplotypes-in-population 128 --min-pruning 2 --adaptive-pruning-initial-error-rate 0.001 --pruning-lod-threshold 2.302585092994046 --max-unpruned-variants 100 --linked-de-bruijn-graph false --disable-artificial-haplotype-recovery false --debug-assembly false --debug-graph-transformations false --capture-assembly-failure-bam false --error-correction-log-odds -Infinity --error-correct-reads false --kmer-length-for-read-error-correction 25 --min-observations-for-kmer-to-be-solid 20 --base-quality-score-threshold 18 --pair-hmm-gap-continuation-penalty 10 --pair-hmm-implementation FASTEST_AVAILABLE --pcr-indel-model CONSERVATIVE --phred-scaled-global-read-mismapping-rate 45 --native-pair-hmm-threads 4 --native-pair-hmm-use-double-precision false --bam-writer-type CALLED_HAPLOTYPES --dont-use-soft-clipped-bases false --min-base-quality-score 10 --smith-waterman JAVA --emit-ref-confidence NONE --max-mnp-distance 1 --force-call-filtered-alleles false --allele-informative-reads-overlap-margin 2 --min-assembly-region-size 50 --max-assembly-region-size 300 --active-probability-threshold 0.002 --max-prob-propagation-distance 50 --force-active false --assembly-region-padding 100 --padding-around-indels 75 --padding-around-snps 20 --padding-around-strs 75 --max-reads-per-alignment-start 50 --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays  --disable-tool-default-read-filters false --max-read-length 2147483647 --min-read-length 30 --minimum-mapping-quality 20 --disable-tool-default-annotations false --enable-all-annotations false\",Version=\"4.1.8.1\",Date=\"November 12, 2020 7:45:52 PM GMT\">`\n",
    "\n",
    "### Header line (starts with CHROM)\n",
    "The special Header line describes each column of the data lines, which immediately follow this line.\n",
    "\n",
    "`#CHROM POS ID REF ALT QUAL FILTER INFO`\n",
    "\n",
    "If your VCF contains per-sample information, the header line will also include a FORMAT field, followed for one field for each sample.\n",
    "\n",
    "`#CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Exome_Normal Exome_Tumor`\n",
    "\n",
    "## Example\n",
    "```\n",
    "##fileformat=VCFv4.2\n",
    "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
    "##INFO=<ID=MBQ,Number=R,Type=Integer,Description=\"median base quality\">\n",
    "##INFO=<ID=MMQ,Number=R,Type=Integer,Description=\"median mapping quality\">\n",
    "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
    "##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n",
    "##FORMAT=<ID=AF,Number=A,Type=Float,Description=\"Allele fractions of alternate alleles in the tumor\">\n",
    "##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\">\n",
    "#CHROM    POS    ID    REF    ALT    QUAL    FILTER    INFO    FORMAT    Exome_Normal    Exome_Tumor\n",
    "chr17\t2364457\t.\tT\tG\t.\tPASS\tMBQ=30,30;MMQ=60,60\tGT:AD:AF:DP\t0/0:85,0:0.011:85\t0/1:43,58:0.573:101\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing VCF - adding readcounts using bam-readcount and VAtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting multialleleic sites using vt decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our VCF might contain variants with multiple alt alleles. In these cases the ALT field of the VCF will have multiple alt alleles in it. Take for example this variant:\n",
    "```\n",
    "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tExome_Normal\tExome_Tumor\n",
    "chr17\t3017916\t.\tCGTGT\tC,CGT\t.\tgermline;multiallelic;normal_artifact\tAS_FilterStatus=weak_evidence|SITE;AS_SB_TABLE=31,0|3,0|9,0;DP=48;ECNT=1;GERMQ=1;MBQ=30,30,30;MFRL=0,0,0;MMQ=60,60,60;MPOS=49,31;NALOD=0.710,-7.297e+00;NLOD=2.65,-6.178e+00;POPAF=6.00,6.00;RPA=16,14,15;RU=GT;STR;STRQ=93;TLOD=6.76,12.45\tGT:AD:AF:DP:F1R2:F2R1:SB\t0/0:9,0,3:0.066,0.271:12:0,0,0:8,0,3:9,0,3,0\t0/1/2:22,3,6:0.117,0.205:31:0,0,0:22,3,6:22,0,9,0\n",
    "```\n",
    "This might happen if both chromsomes have a mutation at the same position, but the exact mutation differs between the two chromosomes. It might also happen if there is a subclonal mutation in some tumor cells. It might also just be an artifact.\n",
    "\n",
    "It is usually easier to process a VCF if these sort of variants are preprocessed to split up multi-allelic sites since some information is encoded on a per-allele basis (e.g., per-allele depth, per-allele VAF). \n",
    "\n",
    "vt decompose is part of the [vt tool package](https://genome.sph.umich.edu/wiki/Vt) and available on quay container at `quay.io/biocontainers/vt:0.57721--hf74b74d_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD/bfx_workshop_week_7:/data -it quay.io/biocontainers/vt:0.57721--hf74b74d_1 vt decompose /data/mutect.filtered.vcf.gz -s -o /data/mutect.filtered.decomposed.vcf.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running vt decompose the above variant is split up into two lines and looks like this:\n",
    "```\n",
    "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tExome_Normal\tExome_Tumor\n",
    "chr17\t3017916\t.\tCGTGT\tC\t.\tgermline;multiallelic;normal_artifact\tAS_FilterStatus=weak_evidence|SITE;AS_SB_TABLE=31,0|3,0|9,0;DP=48;ECNT=1;GERMQ=1;MBQ=30,30;MFRL=0,0;MMQ=60,60;MPOS=49;NALOD=0.71;NLOD=2.65;POPAF=6;RPA=16,14;RU=GT;STR;STRQ=93;TLOD=6.76;OLD_MULTIALLELIC=chr17:3017916:CGTGT/C/CGT\tGT:AD:AF:DP:F1R2:F2R1:SB\t0/0:9,0:0.066:12:0,0:8,0:9,0,3,0\t0/1/.:22,3:0.117:31:0,0:22,3:22,0,9,0\n",
    "chr17\t3017916\t.\tCGTGT\tCGT\t.\tgermline;multiallelic;normal_artifact\tAS_FilterStatus=weak_evidence|SITE;AS_SB_TABLE=31,0|3,0|9,0;DP=48;ECNT=1;GERMQ=1;MBQ=30,30;MFRL=0,0;MMQ=60,60;MPOS=31;NALOD=-7.297;NLOD=-6.178;POPAF=6;RPA=16,15;RU=GT;STR;STRQ=93;TLOD=12.45;OLD_MULTIALLELIC=chr17:3017916:CGTGT/C/CGT\tGT:AD:AF:DP:F1R2:F2R1:SB\t0/0:9,3:0.271:12:0,0:8,3:9,0,3,0\t0/./1:22,6:0.205:31:0,0:22,6:22,0,9,0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bam-readcount\n",
    "Some variant callers will already output read depth and allelic depths but this is useful in cases where this information is not already present in the VCF. This is also useful if you run RNAseq on top of somatic variant calling to add RNA coverage information to your VCF.\n",
    "\n",
    "We will be using the `mgibio/bam_readcount_helper-cwl:1.1.1` docker container to run bam-readcount. This Docker image already has bam-readcount installed and it also contains a script that will take care of creating a region list from your VCF, which is a required input to bam-readcount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required inputs\n",
    "- vcf\n",
    "- sample name\n",
    "- reference fasta\n",
    "- bam file\n",
    "- output file prefix\n",
    "- output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip\n",
    "To quickly find sample names in a VCF, try searching the file for `#CHROM`. This is guaranteed to be part of the header, and the names of any samples included in the file will be present at the end of this line. \n",
    "Normally we would use `grep` to search through a file, but VCF files are often stored `gzip`-compressed to save space. Luckily, `zgrep` is standard alongside grep, and can be used to search compressed files in place, without needing to manually unzip, search, then re-zip. Similar counterparts exist to other standard tools, such as `cat`/`zcat` and `diff`/`zdiff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zgrep '#CHROM' bfx_workshop_week_7/mutect.filtered.decomposed.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD/bfx_workshop_week_7:/data -it mgibio/bam_readcount_helper-cwl:1.1.1 python /usr/bin/bam_readcount_helper.py /data/mutect.filtered.decomposed.vcf.gz Exome_Tumor /data/hla_and_brca_genes.fa /data/tumor.bam Exome_Tumor /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAtools\n",
    "[VAtools](http://www.vatools.org) is a python package that provides a suite of tools that help with processing VCF annotations. We will be using the [vcf-readcount-annotator tool](https://vatools.readthedocs.io/en/latest/vcf_readcount_annotator.html) included with VAtools to write the readcounts calculated in the previous step to our VCF. VAtools is available as a Docker image at `griffithlab/vatools:5.1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD/bfx_workshop_week_7:/data -it griffithlab/vatools:5.1.0 vcf-readcount-annotator /data/mutect.filtered.decomposed.vcf.gz /data/Exome_Tumor_Exome_Tumor_bam_readcount_snv.tsv DNA -t snv -s Exome_Tumor -o /data/mutect.filtered.decomposed.readcount_snvs.vcf.gz\n",
    "!docker run -v $PWD/bfx_workshop_week_7:/data -it griffithlab/vatools:5.1.0 vcf-readcount-annotator /data/mutect.filtered.decomposed.readcount_snvs.vcf.gz /data/Exome_Tumor_Exome_Tumor_bam_readcount_indel.tsv DNA -s Exome_Tumor -t indel -o /data/mutect.filtered.decomposed.readcount_snvs_indel.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing VCFs in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyVCF vs VCFPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyVCF](https://pyvcf.readthedocs.io/en/latest/) is the \"original\" Python VCF parser. Unfortunately, it doesn't appear to be maintained anymore and is incompatible with newer version of setuptools, leading to installation errors. It also doesn't support modifying VCF entries very well. [VCFPy](https://vcfpy.readthedocs.io/en/stable/) was created to solve this problem. For that reason we'll be using VCFPy for the next tasks.\n",
    "\n",
    "First, we need to ensure that the `vcfpy` package is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vcfpy pysam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in a VCF and exploring its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcfpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the VCF reader object from your VCF path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader = vcfpy.Reader.from_path(\"bfx_workshop_week_7/mutect.filtered.decomposed.readcount_snvs_indel.vcf.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which samples are in your VCF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.header.samples.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which FILTERS are defined in the VCF header?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.header.filter_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar methods `info_ids` and `format_ids` exist for the INFO and FORMAT fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information for a specific INFO header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.header.get_info_field_info('DP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information for each variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader = vcfpy.Reader.from_path(\"bfx_workshop_week_7/mutect.filtered.decomposed.readcount_snvs_indel.vcf.gz\")\n",
    "for entry in vcf_reader:\n",
    "    #Get all FILTER fields applied to this variant \n",
    "    print(entry.FILTER)\n",
    "    #Get the VAFs of a variant\n",
    "    print(entry.call_for_sample['Exome_Tumor'].data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After your're done with all processing, you will need to close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering a VCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a filtered VCF so that only variants with a `PASS` filter and a VAF over 0.25 will remain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcfpy\n",
    "vcf_reader = vcfpy.Reader.from_path(\"bfx_workshop_week_7/mutect.filtered.decomposed.readcount_snvs_indel.vcf.gz\")\n",
    "vcf_writer = vcfpy.Writer.from_path(\"bfx_workshop_week_7/mutect.filtered.decomposed.readcount_snvs_indel.pass_vaf_filtered.vcf.gz\", vcf_reader.header)\n",
    "for entry in vcf_reader:\n",
    "    if 'PASS' in entry.FILTER and entry.call_for_sample['Exome_Tumor'].data['AF'][0] > 0.25:\n",
    "        vcf_writer.write_record(entry)\n",
    "vcf_reader.close()\n",
    "vcf_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zgrep -v '#' bfx_workshop_week_7/mutect.filtered.decomposed.readcount_snvs_indel.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zgrep -v '#' bfx_workshop_week_7/mutect.filtered.decomposed.readcount_snvs_indel.pass_vaf_filtered.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a human-readable TSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VCFs can often be hard to read since a lot of information is presented in a condensed manner. Let's output some of its information in an easier understandable TSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcfpy\n",
    "import csv\n",
    "\n",
    "vcf_reader = vcfpy.Reader.from_path(\"bfx_workshop_week_7/mutect.filtered.decomposed.readcount_snvs_indel.pass_vaf_filtered.vcf.gz\")\n",
    "with open(\"bfx_workshop_week_7/mutect.filtered.decomposed.readcount_snvs_indel.pass_vaf_filtered.tsv\", 'w') as out_fh:\n",
    "    headers = ['CHROM', 'POS', 'REF', 'ALT', 'FILTER', 'DEPTH', 'VAF']\n",
    "    tsv_writer = csv.DictWriter(out_fh, delimiter = '\\t', fieldnames = headers)\n",
    "    tsv_writer.writeheader()\n",
    "    for entry in vcf_reader:\n",
    "        out = {\n",
    "            'CHROM': entry.CHROM,\n",
    "            'POS': entry.POS,\n",
    "            'REF': entry.REF,\n",
    "            'ALT': ','.join( [alt.serialize() for alt in entry.ALT] ),\n",
    "            'FILTER': ','.join(entry.FILTER),\n",
    "            'DEPTH': entry.call_for_sample['Exome_Tumor'].data['DP'],\n",
    "            'VAF': ','.join( [str(vaf) for vaf in entry.call_for_sample['Exome_Tumor'].data['AF']] )\n",
    "        }\n",
    "        tsv_writer.writerow(out)\n",
    "vcf_reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat bfx_workshop_week_7/mutect.filtered.decomposed.readcount_snvs_indel.pass_vaf_filtered.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Tips\n",
    "\n",
    "## REPL\n",
    "If you're in a hurry, on an unfamiliar machine, or just don't like Jupyter, but want a similar way to quickly try out some code and see results, try out the python REPL!\n",
    "- This stands for read-eval-print-loop, and functions much like the embedded code snippets in the notebook above, or like REPLs packaged with other languages\n",
    "- Invoke with `python -i`\n",
    "- Quit with `exit()`\n",
    "- Scripts can also be launched interactively with `python -i <script.py>`, and upon exit (whether normally or due to an error), the state is passed to the REPL, and you can run functions from the script, examine variable values, etc\n",
    "\n",
    "## Useful bioinformatics packages\n",
    "- vcfpy\n",
    "- pysam- samtools wrapper\n",
    "- pyyaml- work with YAML files (CWL, the language that our managed workflow are written in, is actually YAML)\n",
    "- pandas & numpy- packages for efficiently working with big data\n",
    "- biopython- a vast collection of bioinformatics tool. Also useful for parsing and writing FASTA files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "- Download the normal bams from here: gs://analysis-workflows-example-data/vcf_parsing_files/normal.bam, gs://analysis-workflows-example-data/vcf_parsing_files/normal.bam.bai\n",
    "- Calculate readcounts for the normal sample and add them to the `mutect.filtered.decomposed.pass_vaf_filtered.vcf.gz` file\n",
    "- Filter the output VCF from the above step to exclude variants where the normal VAF is higher than 0.02\n",
    "- Amend the TSV-creation script to also output the normal VAF on top of the other information\n",
    "- Read Chapter 1 of the the [VCF specification document](https://samtools.github.io/hts-specs/VCFv4.2.pdf) to familiarize yourself further with the VCF format. What are the differences between the FILTER, INFO, and FORMAT fields (i.e., when would you use which field)? What do the Number types A, R, G, and . mean? Make a list of additional questions you might have about the VCF format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
