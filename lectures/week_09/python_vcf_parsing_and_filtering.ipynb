{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFX Workshop Week 9 - Parsing and Filtering with Python\n",
    "\n",
    "## Setup\n",
    "\n",
    "For this module we'll be working with a somatic exome VCF file created by the Mutect variant caller with some basic filtering already done. Let's create a working directory and download this file.\n",
    "\n",
    "Note that some of the following dropbox links may break in the future; all files are mirrored at [box]( https://wustl.app.box.com/folder/149874570252). `wget` will not work for box links, so you will have to follow the link in your browser and download the files that way.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $PWD\n",
    "!mkdir -p $PWD/bfx_workshop_week_09\n",
    "!wget https://www.dropbox.com/s/cwktbkj72va2dci/mutect.filtered.vcf.gz -O $PWD/bfx_workshop_week_09/mutect.filtered.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the reference and tumor bam files used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD/bfx_workshop_week_09:/staging mgibio/data_downloader:0.1.0 gsutil -m cp gs://analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa /staging\n",
    "!docker run -v $PWD/bfx_workshop_week_09:/staging mgibio/data_downloader:0.1.0 gsutil -m cp gs://analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa.fai /staging\n",
    "!wget https://www.dropbox.com/s/7k92tp014f6zzg4/tumor.bam -O $PWD/bfx_workshop_week_09/tumor.bam\n",
    "!wget https://www.dropbox.com/s/mogij2hxuxsur1f/tumor.bam.bai -O $PWD/bfx_workshop_week_09/tumor.bam.bai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed up later steps, let's pull the Docker containers we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull mgibio/bam_readcount_helper-cwl:1.1.1\n",
    "!docker pull quay.io/biocontainers/vt:0.57721--hf74b74d_1\n",
    "!docker pull griffithlab/vatools:5.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to VCF\n",
    "The [Variant Call Format (VCF)](https://samtools.github.io/hts-specs/VCFv4.2.pdf) is a text file format. It contains meta-information header lines and data lines with information about a position in the genome. It can optionally contain genotype information on samples for each position.\n",
    "\n",
    "## Types of data encoded\n",
    "### FILTER\n",
    "Filters that have been applied to a data line\n",
    "\n",
    "### INFO\n",
    "Per-variant data\n",
    "\n",
    "### FORMAT\n",
    "Per-sample data\n",
    "\n",
    "## Meta-information header lines\n",
    "Provide information about how each field is encoded.\n",
    "### File format\n",
    "`##fileformat=VCFv4.2`\n",
    "\n",
    "### FILTER\n",
    "Each FILTER header describes one specific FILTER. The header includes the ID of the FILTER and a description.\n",
    "\n",
    "`##FILTER=<ID=ID,Description=\"description\">`\n",
    "\n",
    "e.g.:\n",
    "\n",
    "`##FILTER=<ID=PASS,Description=\"All filters passed\">`\n",
    "\n",
    "### INFO\n",
    "Each INFO header describes one specific INFO field. The header includes the ID of the INFO field, a Number value describing how many data points will be encoded in the field, a Type describing the data type of each data point in this field, and a Description. Source and Version are optional but can be used to descibe which tool added this field and the version of the tool.\n",
    "\n",
    "`##INFO=<ID=ID,Number=number,Type=type,Description=\"description\",Source=\"source\",Version=\"version\">`\n",
    "\n",
    "e.g.:\n",
    "\n",
    "`##INFO=<ID=MBQ,Number=R,Type=Integer,Description=\"median base quality\">`\n",
    "\n",
    "### FORMAT\n",
    "Each FORMAT header descibes one specific per-sample field. The header includes the ID of the per-sample field a Number value describing how many data points will be encoded in the field, a Type describing the data type of each data point in this field, and a Description.\n",
    "\n",
    "`##FORMAT=<ID=ID,Number=number,Type=type,Description=\"description\">`\n",
    "\n",
    "e.g.:\n",
    "\n",
    "`##FORMAT=<ID=AF,Number=A,Type=Float,Description=\"Allele fractions of alternate alleles in the tumor\">`\n",
    "\n",
    "### Header line (starts with CHROM)\n",
    "The Header line describes each column of the data lines, which immediately follow this line.\n",
    "\n",
    "`#CHROM POS ID REF ALT QUAL FILTER INFO`\n",
    "\n",
    "If your VCF contains per-sample information, the header line will also include a FORMAT field, followed for one field for each sample.\n",
    "\n",
    "`#CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Exome_Normal Exome_Tumor`\n",
    "\n",
    "## Example\n",
    "```\n",
    "##fileformat=VCFv4.2\n",
    "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
    "##INFO=<ID=MBQ,Number=R,Type=Integer,Description=\"median base quality\">\n",
    "##INFO=<ID=MMQ,Number=R,Type=Integer,Description=\"median mapping quality\">\n",
    "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
    "##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n",
    "##FORMAT=<ID=AF,Number=A,Type=Float,Description=\"Allele fractions of alternate alleles in the tumor\">\n",
    "##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\">\n",
    "#CHROM    POS    ID    REF    ALT    QUAL    FILTER    INFO    FORMAT    Exome_Normal    Exome_Tumor\n",
    "chr17\t2364457\t.\tT\tG\t.\tPASS\tMBQ=30,30;MMQ=60,60\tGT:AD:AF:DP\t0/0:85,0:0.011:85\t0/1:43,58:0.573:101\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing VCF - adding readcounts using bam-readcount and VAtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting multialleleic sites using vt decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our VCF might contain variants with multiple alt alleles. In these cases the ALT field of the VCF will have multiple alt alleles in it. Take for example this variant:\n",
    "```\n",
    "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tExome_Normal\tExome_Tumor\n",
    "chr17\t3017916\t.\tCGTGT\tC,CGT\t.\tgermline;multiallelic;normal_artifact\tAS_FilterStatus=weak_evidence|SITE;AS_SB_TABLE=31,0|3,0|9,0;DP=48;ECNT=1;GERMQ=1;MBQ=30,30,30;MFRL=0,0,0;MMQ=60,60,60;MPOS=49,31;NALOD=0.710,-7.297e+00;NLOD=2.65,-6.178e+00;POPAF=6.00,6.00;RPA=16,14,15;RU=GT;STR;STRQ=93;TLOD=6.76,12.45\tGT:AD:AF:DP:F1R2:F2R1:SB\t0/0:9,0,3:0.066,0.271:12:0,0,0:8,0,3:9,0,3,0\t0/1/2:22,3,6:0.117,0.205:31:0,0,0:22,3,6:22,0,9,0\n",
    "```\n",
    "This might happen if both chromsomes have a mutation at the same position, but the exact mutation differs between the two chromosomes. It might also happen if there is a subclonal mutation in some tumor cells. It might also just be an artifact.\n",
    "\n",
    "It is usually easier to process a VCF if these sort of variants are preprocessed to split up multi-allelic sites since some information is encoded on a per-allele basis (e.g., per-allele depth, per-allele VAF). \n",
    "\n",
    "vt decompose is part of the [vt tool package](https://genome.sph.umich.edu/wiki/Vt) and available on quay container at `quay.io/biocontainers/vt:0.57721--hf74b74d_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD/bfx_workshop_week_09:/data -it quay.io/biocontainers/vt:0.57721--hf74b74d_1 vt decompose /data/mutect.filtered.vcf.gz -s -o /data/mutect.filtered.decomposed.vcf.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running vt decompose the above variant is split up into two lines and looks like this:\n",
    "```\n",
    "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tExome_Normal\tExome_Tumor\n",
    "chr17\t3017916\t.\tCGTGT\tC\t.\tgermline;multiallelic;normal_artifact\tAS_FilterStatus=weak_evidence|SITE;AS_SB_TABLE=31,0|3,0|9,0;DP=48;ECNT=1;GERMQ=1;MBQ=30,30;MFRL=0,0;MMQ=60,60;MPOS=49;NALOD=0.71;NLOD=2.65;POPAF=6;RPA=16,14;RU=GT;STR;STRQ=93;TLOD=6.76;OLD_MULTIALLELIC=chr17:3017916:CGTGT/C/CGT\tGT:AD:AF:DP:F1R2:F2R1:SB\t0/0:9,0:0.066:12:0,0:8,0:9,0,3,0\t0/1/.:22,3:0.117:31:0,0:22,3:22,0,9,0\n",
    "chr17\t3017916\t.\tCGTGT\tCGT\t.\tgermline;multiallelic;normal_artifact\tAS_FilterStatus=weak_evidence|SITE;AS_SB_TABLE=31,0|3,0|9,0;DP=48;ECNT=1;GERMQ=1;MBQ=30,30;MFRL=0,0;MMQ=60,60;MPOS=31;NALOD=-7.297;NLOD=-6.178;POPAF=6;RPA=16,15;RU=GT;STR;STRQ=93;TLOD=12.45;OLD_MULTIALLELIC=chr17:3017916:CGTGT/C/CGT\tGT:AD:AF:DP:F1R2:F2R1:SB\t0/0:9,3:0.271:12:0,0:8,3:9,0,3,0\t0/./1:22,6:0.205:31:0,0:22,6:22,0,9,0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bam-readcount\n",
    "Some variant callers will already output read depth and allelic depths but this is useful in cases where this information is not already present in the VCF. This is also useful if you run RNAseq on top of somatic variant calling to add RNA coverage information to your VCF.\n",
    "\n",
    "We will be using the `mgibio/bam_readcount_helper-cwl:1.1.1` docker container to run bam-readcount. This Docker image already has bam-readcount installed and it also contains a script that will take care of creating a region list from your VCF, which is a required input to bam-readcount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required inputs\n",
    "- vcf\n",
    "- sample name\n",
    "- reference fasta\n",
    "- bam file\n",
    "- output file prefix\n",
    "- output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip\n",
    "To quickly find sample names in a VCF, try searching the file for `#CHROM`. This is guaranteed to be part of the header, and the names of any samples included in the file will be present at the end of this line. \n",
    "Normally we would use `grep` to search through a file, but VCF files are often stored `gzip`-compressed to save space. Luckily, `zgrep` is standard alongside grep, and can be used to search compressed files in place, without needing to manually unzip, search, then re-zip. Similar counterparts exist to other standard tools, such as `cat`/`zcat` and `diff`/`zdiff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zgrep '#CHROM' bfx_workshop_week_09/mutect.filtered.decomposed.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD/bfx_workshop_week_09:/data -it mgibio/bam_readcount_helper-cwl:1.1.1 python /usr/bin/bam_readcount_helper.py /data/mutect.filtered.decomposed.vcf.gz Exome_Tumor /data/hla_and_brca_genes.fa /data/tumor.bam Exome_Tumor /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAtools\n",
    "[VAtools](http://www.vatools.org) is a python package that provides a suite of tools that help with processing VCF annotations. We will be using the [vcf-readcount-annotator tool](https://vatools.readthedocs.io/en/latest/vcf_readcount_annotator.html) included with VAtools to write the readcounts calculated in the previous step to our VCF. VAtools is available as a Docker image at `griffithlab/vatools:4.1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD/bfx_workshop_week_09:/data -it griffithlab/vatools:5.0.1 vcf-readcount-annotator /data/mutect.filtered.decomposed.vcf.gz /data/Exome_Tumor_Exome_Tumor_bam_readcount_snv.tsv DNA -t snv -s Exome_Tumor -o /data/mutect.filtered.decomposed.readcount_snvs.vcf.gz\n",
    "!docker run -v $PWD/bfx_workshop_week_09:/data -it griffithlab/vatools:5.0.1 vcf-readcount-annotator /data/mutect.filtered.decomposed.readcount_snvs.vcf.gz /data/Exome_Tumor_Exome_Tumor_bam_readcount_indel.tsv DNA -s Exome_Tumor -t indel -o /data/mutect.filtered.decomposed.readcount_snvs_indel.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing VCFs in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyVCF vs VCFPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyVCF](https://pyvcf.readthedocs.io/en/latest/) is the \"original\" Python VCF parser. Unfortunately, it doesn't appear to be maintained anymore and is incompatible with newer version of setuptools, leading to installation errors. It also doesn't support modifying VCF entries very well. [VCFPy](https://vcfpy.readthedocs.io/en/stable/) was created to solve this problem. For that reason we'll be using VCFPy for the next tasks.\n",
    "\n",
    "First, we need to ensure that the `vcfpy` package is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vcfpy pysam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in a VCF and exploring its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcfpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the VCF reader object from your VCF path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader = vcfpy.Reader.from_path(\"bfx_workshop_week_09/mutect.filtered.decomposed.readcount_snvs_indel.vcf.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which samples are in your VCF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.header.samples.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which FILTERS are defined in the VCF header?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.header.filter_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar methods `info_ids` and `format_ids` exist for the INFO and FORMAT fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information for a specific INFO header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.header.get_info_field_info('DP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information for each variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader = vcfpy.Reader.from_path(\"bfx_workshop_week_09/mutect.filtered.decomposed.readcount_snvs_indel.vcf.gz\")\n",
    "for entry in vcf_reader:\n",
    "    #Get all FILTER fields applied to this variant \n",
    "    print(entry.FILTER)\n",
    "    #Get the VAFs of a variant\n",
    "    print(entry.call_for_sample['Exome_Tumor'].data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After your're done with all processing, you will need to close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering a VCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a filtered VCF so that only variants with a `PASS` filter and a VAF over 0.25 will remain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcfpy\n",
    "vcf_reader = vcfpy.Reader.from_path(\"bfx_workshop_week_09/mutect.filtered.decomposed.readcount_snvs_indel.vcf.gz\")\n",
    "vcf_writer = vcfpy.Writer.from_path(\"bfx_workshop_week_09/mutect.filtered.decomposed.readcount_snvs_indel.pass_vaf_filtered.vcf.gz\", vcf_reader.header)\n",
    "for entry in vcf_reader:\n",
    "    if 'PASS' in entry.FILTER and entry.call_for_sample['Exome_Tumor'].data['AF'][0] > 0.25:\n",
    "        vcf_writer.write_record(entry)\n",
    "vcf_reader.close()\n",
    "vcf_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zgrep -v '#' bfx_workshop_week_09/mutect.filtered.decomposed.readcount_snvs_indel.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zgrep -v '#' bfx_workshop_week_09/mutect.filtered.decomposed.readcount_snvs_indel.pass_vaf_filtered.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a human-readable TSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VCFs can often be hard to read since a lot of information is presented in a condensed manner. Let's output some of its information in an easier understandable TSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcfpy\n",
    "import csv\n",
    "\n",
    "vcf_reader = vcfpy.Reader.from_path(\"bfx_workshop_week_09/mutect.filtered.decomposed.readcount_snvs_indel.pass_vaf_filtered.vcf.gz\")\n",
    "with open(\"bfx_workshop_week_09/mutect.filtered.decomposed.readcount_snvs_indel.pass_vaf_filtered.tsv\", 'w') as out_fh:\n",
    "    headers = ['CHROM', 'POS', 'REF', 'ALT', 'FILTER', 'DEPTH', 'VAF']\n",
    "    tsv_writer = csv.DictWriter(out_fh, delimiter = '\\t', fieldnames = headers)\n",
    "    tsv_writer.writeheader()\n",
    "    for entry in vcf_reader:\n",
    "        out = {\n",
    "            'CHROM': entry.CHROM,\n",
    "            'POS': entry.POS,\n",
    "            'REF': entry.REF,\n",
    "            'ALT': ','.join( [alt.serialize() for alt in entry.ALT] ),\n",
    "            'FILTER': ','.join(entry.FILTER),\n",
    "            'DEPTH': entry.call_for_sample['Exome_Tumor'].data['DP'],\n",
    "            'VAF': ','.join( [str(vaf) for vaf in entry.call_for_sample['Exome_Tumor'].data['AF']] )\n",
    "        }\n",
    "        tsv_writer.writerow(out)\n",
    "vcf_reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat bfx_workshop_week_09/mutect.filtered.decomposed.readcount_snvs_indel.pass_vaf_filtered.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Tips\n",
    "\n",
    "## REPL\n",
    "If you're in a hurry, on an unfamiliar machine, or just don't like Jupyter, but want a similar way to quickly try out some code and see results, try out the python REPL!\n",
    "- This stands for read-eval-print-loop, and functions much like the embedded code snippets in the notebook above, or like REPLs packaged with other languages\n",
    "- Invoke with `python -i`\n",
    "- Quit with `exit()`\n",
    "- Scripts can also be launched interactively with `python -i <script.py>`, and upon exit (whether normally or due to an error), the state is passed to the REPL, and you can run functions from the script, examine variable values, etc\n",
    "\n",
    "## Useful bioinformatics packages\n",
    "- vcfpy\n",
    "- pysam- samtools wrapper\n",
    "- pyyaml- work with YAML files (CWL, the language that our managed workflow are written in, is actually YAML)\n",
    "- pandas & numpy- packages for efficiently working with big data\n",
    "- biopython- a vast collection of bioinformatics tool. Also useful for parsing and writing FASTA files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "- Download the normal bams from here: https://www.dropbox.com/s/jhru5qu4bxcmfwq/normal.bam, https://www.dropbox.com/s/4gimazw35rcxr8x/normal.bam.bai\n",
    "- Calculate readcounts for the normal sample and add them to the `mutect.filtered.decomposed.pass_vaf_filtered.vcf.gz` file\n",
    "- Filter the output VCF from the above step to exclude variants where the normal VAF is higher than 0.02\n",
    "- Amend the TSV-creation script to also output the normal VAF on top of the other information\n",
    "- Read Chapter 1 of the the [VCF specification document](https://samtools.github.io/hts-specs/VCFv4.2.pdf) to familiarize yourself further with the VCF format. What are the differences between the FILTER, INFO, and FORMAT fields (i.e., when would you use which field)? What do the Number types A, R, G, and . mean? Make a list of additional questions you might have about the VCF format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
